import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

# SÉ™hifÉ™ konfiqurasiyasÄ±
st.set_page_config(page_title="Forex Analiz XÃ¼lasÉ™si", layout="wide")

def translate_to_az(text):
    """SadÉ™ lÃ¼ÄŸÉ™t É™saslÄ± vÉ™ ya sÃ¼ni intellekt É™vÉ™zi tÉ™rcÃ¼mÉ™ (NÃ¼munÉ™ Ã¼Ã§Ã¼n)"""
    translations = {
        "Technical Analysis": "Texniki Analiz",
        "Forecast": "Proqnoz",
        "US Dollar": "ABÅ DollarÄ±",
        "Gold": "QÄ±zÄ±l",
        "Silver": "GÃ¼mÃ¼ÅŸ",
        "Bullish": "ArtÄ±m meyilli",
        "Bearish": "EniÅŸ meyilli",
        "Buying": "AlÄ±ÅŸ",
        "Selling": "SatÄ±ÅŸ"
    }
    for eng, aze in translations.items():
        text = text.replace(eng, aze)
    return text

def extract_levels(text):
    """MÉ™tndÉ™n rÉ™qÉ™mlÉ™ri (Entry, TP, SL) tapmaÄŸa Ã§alÄ±ÅŸÄ±r"""
    levels = re.findall(r"(\d+\.\d+)", text)
    return ", ".join(levels) if levels else "Qeyd olunmayÄ±b"

def get_dailyforex():
    url = "https://www.dailyforex.com/forex-technical-analysis/page-1"
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    analizler = []
    items = soup.find_all('div', class_='daily-analysis-item', limit=10)
    
    for item in items:
        title = item.find('h2').text.strip()
        desc = item.find('p').text.strip()
        link = "https://www.dailyforex.com" + item.find('a')['href']
        
        analizler.append({
            "MÉ™nbÉ™": "DailyForex",
            "Analiz": translate_to_az(title),
            "XÃ¼lasÉ™": translate_to_az(desc[:150] + "..."),
            "SÉ™viyyÉ™lÉ™r (E/TP/SL)": extract_levels(desc),
            "Link": link
        })
    return analizler

def get_fxstreet():
    url = "https://www.fxstreet.com.tr/analysis/latest"
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    analizler = []
    # FXStreet TR strukturu Ã¼Ã§Ã¼n uyÄŸunlaÅŸdÄ±rma
    items = soup.find_all('article', limit=10)
    
    for item in items:
        title_el = item.find('h4') or item.find('h2')
        if not title_el: continue
        
        title = title_el.text.strip()
        link = item.find('a')['href']
        
        analizler.append({
            "MÉ™nbÉ™": "FXStreet TR",
            "Analiz": title,
            "XÃ¼lasÉ™": "ÆtraflÄ± linkdÉ™",
            "SÉ™viyyÉ™lÉ™r (E/TP/SL)": "MÉ™qalÉ™dÉ™",
            "Link": link
        })
    return analizler

# UI HissÉ™si
st.title("ğŸ“Š Forex Son 10 Analiz (XÃ¼lasÉ™)")

if st.button('MÉ™lumatlarÄ± YenilÉ™'):
    with st.spinner('AnalizlÉ™r toplanÄ±r...'):
        try:
            df_data = get_dailyforex() + get_fxstreet()
            df = pd.DataFrame(df_data)
            
            # CÉ™dvÉ™li gÃ¶stÉ™r
            st.table(df)
            
            for i, row in df.iterrows():
                with st.expander(f"{row['MÉ™nbÉ™']}: {row['Analiz']}"):
                    st.write(f"**XÃ¼lasÉ™:** {row['XÃ¼lasÉ™']}")
                    st.write(f"**Ehtimal olunan sÉ™viyyÉ™lÉ™r:** {row['SÉ™viyyÉ™lÉ™r (E/TP/SL)']}")
                    st.write(f"[MÉ™nbÉ™yÉ™ keÃ§id]({row['Link']})")
        except Exception as e:
            st.error(f"XÉ™ta baÅŸ verdi: {e}")
else:
    st.info("AnalizlÉ™ri gÃ¶rmÉ™k Ã¼Ã§Ã¼n 'YenilÉ™' dÃ¼ymÉ™sinÉ™ basÄ±n.")

st.sidebar.markdown("""
### NecÉ™ iÅŸlÉ™yir?
1. **DailyForex** vÉ™ **FXStreet TR** saytlarÄ±na sorÄŸu gÃ¶ndÉ™rir.
2. Æn son 10 analizi skan edir.
3. BaÅŸlÄ±qlarÄ± AZ dilinÉ™ Ã§evirir vÉ™ mÉ™tndÉ™ki rÉ™qÉ™mlÉ™ri ayÄ±rÄ±r.
""")
