import streamlit as st
import pandas as pd
import feedparser
import google.generativeai as genai
# VACÄ°B: AÅŸaÄŸÄ±dakÄ± iki sÉ™tir xÉ™talarÄ± hÉ™ll edir
import requests
from bs4 import BeautifulSoup 
from urllib.parse import quote
import time
import random

# --- KONFÄ°QURASÄ°YA ---
API_KEY = "AIzaSyCYMzC7vax4vCA0FLDxeqIeHBwxHklUnao" 

try:
    genai.configure(api_key=API_KEY)
    ai_model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"AI XÉ™tasÄ±: {e}")

st.set_page_config(page_title="Forex Deep AI (Safe)", page_icon="ğŸ›¡ï¸", layout="wide")

def get_deep_analysis(title, summary_text):
    """Google-un verdiyi xÃ¼lasÉ™ É™sasÄ±nda analiz edir"""
    prompt = f"""
    Forex analitikisÉ™n. Bu mÉ™lumatÄ± oxu:
    BAÅLIQ: {title}
    MÆTN: {summary_text}
    
    TapÅŸÄ±rÄ±q:
    1. QÉ™rar: LONG, SHORT vÉ™ ya NEYTRAL?
    2. SÉ™bÉ™b: AzÉ™rbaycan dilindÉ™ 1 cÃ¼mlÉ™.
    3. SÉ™viyyÉ™lÉ™r: Varsa Entry, SL, TP qiymÉ™tlÉ™ri.
    
    Format: [QÆRAR] | [Ä°ZAH] | [SÆVÄ°YYÆ]
    """
    try:
        response = ai_model.generate_content(prompt)
        parts = response.text.split("|")
        
        decision = "ğŸŸ¡ NEYTRAL"
        if "LONG" in parts[0].upper(): decision = "ğŸŸ¢ LONG"
        elif "SHORT" in parts[0].upper(): decision = "ğŸ”´ SHORT"
        
        reason = parts[1].strip() if len(parts) > 1 else "Trend tÉ™hlili."
        levels = parts[2].strip() if len(parts) > 2 else "MÉ™lumat yoxdur."
        
        return decision, reason, levels
    except:
        return None, None, None

# --- Ä°NTERFEYS ---
st.title("ğŸ›¡ï¸ Bloklanmayan DÉ™rin AI Analiz")
st.info("Bu versiya Google-un tÉ™hlÃ¼kÉ™siz bazasÄ±ndan istifadÉ™ edir vÉ™ saytlar tÉ™rÉ™findÉ™n bloklanmÄ±r.")

if st.button('AnalizlÉ™ri Bir-Bir GÉ™tir'):
    sources = [
        ("DailyForex", "dailyforex.com", "forex signals technical"),
        ("FXStreet", "fxstreet.com", "price forecast analysis"),
        ("TradingView", "tradingview.com", "gold eurusd news")
    ]
    
    container = st.container()
    total_count = 0
    
    for src_name, site_url, query in sources:
        # RSS vasitÉ™silÉ™ Google News-dan mÉ™lumat alÄ±rÄ±q
        rss_url = f"https://news.google.com/rss/search?q={quote('site:'+site_url+' '+query)}&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(rss_url)
        
        for entry in feed.entries[:10]:
            # HÉ™r analiz arasÄ± kiÃ§ik fasilÉ™
            time.sleep(random.uniform(0.1, 0.4))
            
            # BeautifulSoup xÉ™tasÄ±nÄ± burada hÉ™ll etdik:
            raw_html = entry.summary if 'summary' in entry else ""
            clean_text = BeautifulSoup(raw_html, "html.parser").get_text()
            
            decision, reason, levels = get_deep_analysis(entry.title, clean_text)
            
            if decision:
                total_count += 1
                with container:
                    with st.expander(f"{decision} | {entry.title.split(' - ')[0]}", expanded=True):
                        st.markdown(f"**MÉ™nbÉ™:** `{src_name}`")
                        st.success(f"**AI TÉ™hlili:** {reason}")
                        st.warning(f"**TÉ™xmini SÉ™viyyÉ™lÉ™r:** {levels}")
                        st.link_button("MÉ™nbÉ™yÉ™ bax", entry.link)

    if total_count == 0:
        st.error("MÉ™lumat tapÄ±lmadÄ±. Ä°nternet baÄŸlantÄ±sÄ±nÄ± vÉ™ ya API aÃ§arÄ±nÄ± yoxlayÄ±n.")
    else:
        st.balloons()
        
