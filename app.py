import streamlit as st
import pandas as pd
import feedparser
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import time
import random

# --- KONFÄ°QURASÄ°YA ---
API_KEY = "AIzaSyCYMzC7vax4vCA0FLDxeqIeHBwxHklUnao" 

try:
    genai.configure(api_key=API_KEY)
    ai_model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"AI Konfiqurasiya xÉ™tasÄ±: {e}")

st.set_page_config(page_title="Forex Deep 10 Pro", page_icon="ğŸ§ ", layout="wide")

def get_content_smart(url):
    """Bloklanmadan mÉ™qalÉ™ mÉ™tni Ã§É™kir"""
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    ]
    try:
        # HÉ™r dÉ™fÉ™ fÉ™rqli User-Agent istifadÉ™ edÉ™rÉ™k saytÄ± aldadÄ±rÄ±q
        headers = {'User-Agent': random.choice(user_agents)}
        response = requests.get(url, headers=headers, timeout=12)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            # YalnÄ±z É™sas mÉ™qalÉ™ gÃ¶vdÉ™sini tapmaÄŸa Ã§alÄ±ÅŸÄ±rÄ±q
            paragraphs = soup.find_all('p')
            text = " ".join([p.get_text() for p in paragraphs if len(p.get_text()) > 50])
            return text[:4500] if len(text) > 200 else None
    except:
        return None
    return None

def ai_deep_analyze(content):
    """MÉ™tni oxuyub LONG/SHORT tÉ™yin edir"""
    prompt = f"""
    SÉ™n peÅŸÉ™kar treyder vÉ™ analitikisÉ™n. AÅŸaÄŸÄ±dakÄ± analizi TAM OXU:
    "{content}"
    
    TÆLÆB:
    1. QÉ™rar: LONG, SHORT vÉ™ ya NEYTRAL? (MÉ™tndÉ™ki texniki gÃ¶stÉ™ricilÉ™rÉ™ É™saslan).
    2. SÉ™bÉ™b: AzÉ™rbaycan dilindÉ™ 1 cÃ¼mlÉ™lik Ã§ox konkret izah.
    3. SÉ™viyyÉ™lÉ™r: Varsa Entry, SL, TP qiymÉ™tlÉ™rini Ã§Ä±xar.
    
    Format: [QÆRAR] | [Ä°ZAH] | [SÆVÄ°YYÆLÆR]
    """
    try:
        response = ai_model.generate_content(prompt)
        parts = response.text.split("|")
        
        decision_raw = parts[0].upper()
        decision = "ğŸŸ¡ NEYTRAL"
        if "LONG" in decision_raw: decision = "ğŸŸ¢ LONG"
        elif "SHORT" in decision_raw: decision = "ğŸ”´ SHORT"
        
        summary = parts[1].strip() if len(parts) > 1 else "Analiz dÉ™rindÉ™n emal edildi."
        levels = parts[2].strip() if len(parts) > 2 else "MÉ™tndÉ™ konkret rÉ™qÉ™m tapÄ±lmadÄ±."
        
        return decision, summary, levels
    except:
        return None, None, None

# --- UI ---
st.title("ğŸ§  Deep AI: 10 Analizin Tam TÉ™hlili")
st.info("Sistem baÅŸlÄ±qlara baxmÄ±r, 30-a yaxÄ±n mÉ™qalÉ™nin daxilinÉ™ girib real siqnallarÄ± axtarÄ±r.")

if st.button('Analizi BaÅŸlat (DÉ™rin AxtarÄ±ÅŸ)'):
    sources = [
        ("DailyForex", "dailyforex.com", "forex signals technical analysis"),
        ("FXStreet", "fxstreet.com", "price forecast today"),
        ("TradingView", "tradingview.com", "eurusd gold analysis")
    ]
    
    all_results = []
    progress = st.progress(0)
    status = st.empty()
    
    # BÃ¼tÃ¼n linklÉ™ri toplayÄ±rÄ±q
    entries_to_process = []
    for src, url, q in sources:
        feed = feedparser.parse(f"https://news.google.com/rss/search?q={quote('site:'+url+' '+q)}&hl=en-US&gl=US&ceid=US:en")
        for e in feed.entries[:10]:
            entries_to_process.append((src, e))

    total = len(entries_to_process)
    
    for i, (src, entry) in enumerate(entries_to_process):
        status.text(f"MÉ™qalÉ™ oxunur ({i+1}/{total}): {entry.title[:45]}...")
        progress.progress((i + 1) / total)
        
        # 1. Sayta daxil ol
        full_text = get_content_smart(entry.link)
        
        if full_text:
            # 2. AI Analizi
            decision, summary, levels = ai_deep_analyze(full_text)
            if decision:
                all_results.append({
                    "MÉ™nbÉ™": src,
                    "BaÅŸlÄ±q": entry.title.split(" - ")[0],
                    "QÉ™rar": decision,
                    "Ä°zah": summary,
                    "SÉ™viyyÉ™lÉ™r": levels,
                    "Link": entry.link
                })
        
        # BLOKLANMAMAQ ÃœÃ‡ÃœN VACÄ°B: HÉ™r mÉ™qalÉ™ arasÄ± tÉ™sadÃ¼fi fasilÉ™
        time.sleep(random.uniform(0.5, 1.5))

    status.success(f"Analiz tamamlandÄ±! {len(all_results)} dÉ™rin analiz tapÄ±ldÄ±.")
    
    if all_results:
        df = pd.DataFrame(all_results)
        st.subheader("ğŸ“‹ AI Siqnal CÉ™dvÉ™li")
        st.dataframe(df[['MÉ™nbÉ™', 'BaÅŸlÄ±q', 'QÉ™rar']], use_container_width=True)
        
        for item in all_results:
            with st.expander(f"{item['QÉ™rar']} | {item['BaÅŸlÄ±q']}"):
                st.markdown(f"**AI TÉ™hlili:** {item['Ä°zah']}")
                st.code(f"Texniki SÉ™viyyÉ™lÉ™r: {item['SÉ™viyyÉ™lÉ™r']}")
                st.link_button("MÉ™nbÉ™ni AÃ§", item['Link'])
    else:
        st.error("Saytlar giriÅŸi blokladÄ±. ZÉ™hmÉ™t olmasa 5-10 dÉ™qiqÉ™ sonra yenidÉ™n yoxlayÄ±n.")
    
